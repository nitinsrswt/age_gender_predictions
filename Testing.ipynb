{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3fa934",
   "metadata": {},
   "source": [
    "##  TESTING."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86729f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model # load_model is to call the trained model, that is model.h5 that we have created.\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "793ab0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath = \"./model.h5\" # Giving the path of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83467104",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(modelPath) # Loading the model by the help of load_model from the path we have specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8914b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = r\"./\" # Defining the output path for the predicted file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24b6276b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePath = r\"./IMG_20191117_171753.jpg\" # Defining the path for the image to be given as input while test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "692a7d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa889ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = cv2.imread(imagePath) # Reading the image file from the path provided and saving it in the \"pic\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e90e7840",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(pic,cv2.COLOR_BGR2GRAY) # Converting from BGR to GRAYSCALE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f2227af",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_cascade.detectMultiScale(gray,1.3,5) # Using for face area detection, as we discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9ce49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = [] # Creating empty list, age.\n",
    "gender = [] # Creating empty list gender.\n",
    "for (x,y,w,h) in faces:\n",
    "  img = gray[y-50:y+40+h,x-10:x+10+w] \n",
    "  img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB) # Converting our image from GRAY to RGB, as we have extracted the features.\n",
    "  img = cv2.resize(img,(200,200)) # Resizing the original image to 200 X 200.\n",
    "  predict = model.predict(np.array(img).reshape(-1,200,200,3)) # Predicting from our imported model, after changing the image into an array and reshaping it.\n",
    "  age.append(predict[0]) # Appending predicted age from predict variable in age list.\n",
    "  gender.append(np.argmax(predict[1])) # Appending the maximum, that is the value with more weight in gender list from the predicted values.\n",
    "  gend = np.argmax(predict[1]) # Keeping the gender value in seperate variable to change the categorical value into string.\n",
    "  if gend == 0:\n",
    "    gend = 'Man'\n",
    "    col = (255,0,0)\n",
    "  else:\n",
    "    gend = 'Female'\n",
    "    col = (203,12,255)\n",
    "  cv2.rectangle(pic,(x,y),(x+w,y+h),(0,225,0),4)\n",
    "  cv2.putText(pic,\"Age : \"+str(int(predict[0]))+\" / \"+str(gend),(x,y),cv2.FONT_HERSHEY_SIMPLEX,w*0.005,col,4) # Writing the predicted values on the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9034f48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"predicted2.jpg\",pic) # Saving the image to our output path by the name we provided below."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
